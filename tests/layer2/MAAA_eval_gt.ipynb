{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55432f28-0cd4-4fc2-adf6-36d3afeabc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/makserveru/Documents/code/algoverse/MAAA/src/layer2/prune/MAAA\n",
      "/home/makserveru/Documents/code/algoverse/MAAA/src/layer2/prune/MAAA\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import inspect\n",
    "\n",
    "\n",
    "parentdir = (Path(os.getcwd()) / '..' / '..' / 'src' / 'layer2' / 'prune' / 'MAAA').resolve()\n",
    "\n",
    "parent_path = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "\n",
    "module_path = os.path.join(parent_path, \"src\", \"layer2\", \"prune\", \"MAAA\")\n",
    "\n",
    "sys.path.append(str(parentdir))\n",
    "print(module_path)\n",
    "print(parentdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80a590d8-23e0-4d2e-9ba0-98271694373c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/makserveru/Documents/code/algoverse/MAAA/src/layer2/prune/MAAA/fpt2_gt.py\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'modeling_fpt2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfpt2_gt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/algoverse/MAAA/src/layer2/prune/MAAA/fpt2_gt.py:74\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[34m__file__\u001b[39m)\n\u001b[32m     68\u001b[39m sys.path.append(\n\u001b[32m     69\u001b[39m     os.path.join(\n\u001b[32m     70\u001b[39m         os.getcwd(),\n\u001b[32m     71\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msrc/layer2/modeling/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     72\u001b[39m     )\n\u001b[32m     73\u001b[39m )   \u001b[38;5;66;03m# Very hacky but the imports are annoying otherwise\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodeling_fpt2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FPT2LMHeadModel\n\u001b[32m     76\u001b[39m require_version(\u001b[33m\"\u001b[39m\u001b[33mdatasets>=1.8.0\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mTo fix: pip install -r examples/pytorch/text-classification/requirements.txt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     77\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'modeling_fpt2'"
     ]
    }
   ],
   "source": [
    "import fpt2_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9731af2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayer2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprune\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mMAAA\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fpt2_gt\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Seq2SeqTrainingArguments\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from src.layer2.prune.MAAA import fpt2_gt\n",
    "from transformers import Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31a2171-85eb-4740-bd2f-247d0c8ac95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = fpt2_gt.ModelArguments(\n",
    "    cache_dir=None, \n",
    "    model_revision='main', \n",
    "    token=None, \n",
    "    use_auth_token=None, \n",
    "    trust_remote_code=False, \n",
    "    ignore_mismatched_sizes=False, \n",
    "    initialize_from='gpt2'\n",
    ")\n",
    "\n",
    "data_args = fpt2_gt.DataTrainingArguments(\n",
    "    dataset_path='./data/datasets/gt/', \n",
    "    train_split='train', \n",
    "    max_train_samples=1000000, \n",
    "    max_eval_samples=150, \n",
    "    overwrite_cache=False, \n",
    "    max_seq_length=64, \n",
    "    start_edge_sparsity=0.0, \n",
    "    target_edge_sparsity=0.985, \n",
    "    start_layer_sparsity=0.0, \n",
    "    target_layer_sparsity=0.68, \n",
    "    stop_optimizing_layer_if_higher_sparsity=False, \n",
    "    num_sparsity_warmup_steps=2500, \n",
    "    edge_learning_rate=0.8, \n",
    "    layer_learning_rate=0.8, \n",
    "    reg_edge_learning_rate=0.8, \n",
    "    reg_layer_learning_rate=0.8, \n",
    "    warmup_type='linear', \n",
    "    with_embedding_nodes=True, \n",
    "    disable_linear_reg_term=False, \n",
    "    disable_node_loss=True\n",
    ")\n",
    "\n",
    "\n",
    "train_args = Seq2SeqTrainingArguments(\n",
    "    _n_gpu=1,\n",
    "    accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
    "    adafactor=False,\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.999,\n",
    "    adam_epsilon=1e-08,\n",
    "    auto_find_batch_size=False,\n",
    "    batch_eval_metrics=False,\n",
    "    bf16=False,\n",
    "    bf16_full_eval=False,\n",
    "    data_seed=None,\n",
    "    dataloader_drop_last=False,\n",
    "    dataloader_num_workers=0,\n",
    "    dataloader_persistent_workers=False,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_prefetch_factor=None,\n",
    "    ddp_backend=None,\n",
    "    ddp_broadcast_buffers=None,\n",
    "    ddp_bucket_cap_mb=None,\n",
    "    ddp_find_unused_parameters=None,\n",
    "    ddp_timeout=1800,\n",
    "    debug=[],\n",
    "    deepspeed=None,\n",
    "    disable_tqdm=False,\n",
    "    dispatch_batches=None,\n",
    "    do_eval=True,\n",
    "    do_predict=False,\n",
    "    do_train=True,\n",
    "    eval_accumulation_steps=16,\n",
    "    eval_delay=0,\n",
    "    eval_do_concat_batches=True,\n",
    "    eval_on_start=False,\n",
    "    eval_steps=64.0,\n",
    "    eval_strategy=IntervalStrategy.NO,\n",
    "    eval_use_gather_object=False,\n",
    "    evaluation_strategy=None,\n",
    "    fp16=False,\n",
    "    fp16_backend=auto,\n",
    "    fp16_full_eval=False,\n",
    "    fp16_opt_level=O1,\n",
    "    fsdp=[],\n",
    "    fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
    "    fsdp_min_num_params=0,\n",
    "    fsdp_transformer_layer_cls_to_wrap=None,\n",
    "    full_determinism=False,\n",
    "    generation_config=None,\n",
    "    generation_max_length=None,\n",
    "    generation_num_beams=None,\n",
    "    gradient_accumulation_steps=1,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs=None,\n",
    "    greater_is_better=None,\n",
    "    group_by_length=False,\n",
    "    half_precision_backend=auto,\n",
    "    hub_always_push=False,\n",
    "    hub_model_id=None,\n",
    "    hub_private_repo=False,\n",
    "    hub_strategy=HubStrategy.EVERY_SAVE,\n",
    "    hub_token=<HUB_TOKEN>,\n",
    "    ignore_data_skip=False,\n",
    "    include_inputs_for_metrics=False,\n",
    "    include_num_input_tokens_seen=False,\n",
    "    include_tokens_per_second=False,\n",
    "    jit_mode_eval=False,\n",
    "    label_names=None,\n",
    "    label_smoothing_factor=0.0,\n",
    "    learning_rate=5e-05,\n",
    "    length_column_name=length,\n",
    "    load_best_model_at_end=False,\n",
    "    local_rank=0,\n",
    "    log_level=passive,\n",
    "    log_level_replica=warning,\n",
    "    log_on_each_node=True,\n",
    "    logging_dir=./data/runs/gt-wo_node_loss-elr0.8-llr0.8-relr0.8-rllr0.8-es0.985-ns0.68-t3000/runs/Jul10_19-24-07_makserveru-Dell-G15-5511,\n",
    "    logging_first_step=False,\n",
    "    logging_nan_inf_filter=True,\n",
    "    logging_steps=8,\n",
    "    logging_strategy=IntervalStrategy.STEPS,\n",
    "    lr_scheduler_kwargs={},\n",
    "    lr_scheduler_type=SchedulerType.LINEAR,\n",
    "    max_grad_norm=1.0,\n",
    "    max_steps=3000,\n",
    "    metric_for_best_model=None,\n",
    "    mp_parameters=,\n",
    "    neftune_noise_alpha=None,\n",
    "    no_cuda=False,\n",
    "    num_train_epochs=3.0,\n",
    "    optim=OptimizerNames.ADAMW_TORCH,\n",
    "    optim_args=None,\n",
    "    optim_target_modules=None,\n",
    "    output_dir=./data/runs/gt-wo_node_loss-elr0.8-llr0.8-relr0.8-rllr0.8-es0.985-ns0.68-t3000/,\n",
    "    overwrite_output_dir=False,\n",
    "    past_index=-1,\n",
    "    per_device_eval_batch_size=16,\n",
    "    per_device_train_batch_size=32,\n",
    "    predict_with_generate=False,\n",
    "    prediction_loss_only=False,\n",
    "    push_to_hub=False,\n",
    "    push_to_hub_model_id=None,\n",
    "    push_to_hub_organization=None,\n",
    "    push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
    "    ray_scope=last,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=['wandb'],\n",
    "    restore_callback_states_from_checkpoint=False,\n",
    "    resume_from_checkpoint=None,\n",
    "    run_name=./data/runs/gt-wo_node_loss-elr0.8-llr0.8-relr0.8-rllr0.8-es0.985-ns0.68-t3000/,\n",
    "    save_on_each_node=False,\n",
    "    save_only_model=False,\n",
    "    save_safetensors=True,\n",
    "    save_steps=64,\n",
    "    save_strategy=IntervalStrategy.STEPS,\n",
    "    save_total_limit=1,\n",
    "    seed=42,\n",
    "    skip_memory_metrics=True,\n",
    "    sortish_sampler=False,\n",
    "    split_batches=None,\n",
    "    tf32=None,\n",
    "    torch_compile=False,\n",
    "    torch_compile_backend=None,\n",
    "    torch_compile_mode=None,\n",
    "    torch_empty_cache_steps=None,\n",
    "    torchdynamo=None,\n",
    "    tpu_metrics_debug=False,\n",
    "    tpu_num_cores=None,\n",
    "    use_cpu=False,\n",
    "    use_ipex=False,\n",
    "    use_legacy_prediction_loop=False,\n",
    "    use_liger_kernel=False,\n",
    "    use_mps_device=False,\n",
    "    warmup_ratio=0.0,\n",
    "    warmup_steps=200,\n",
    "    weight_decay=0.0,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
